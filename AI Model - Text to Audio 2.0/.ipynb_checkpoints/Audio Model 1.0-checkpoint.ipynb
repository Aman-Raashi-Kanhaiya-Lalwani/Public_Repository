{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe94cfc-9dbd-48de-9a4b-5bafa6b17bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core + UI\n",
    "!pip install --quiet \"gradio==4.44.0\" langdetect PyPDF2 python-docx python-pptx\n",
    "\n",
    "# Audio stack (versions pinned for stability with Jupyter)\n",
    "!pip install --quiet \"numpy==1.26.4\" \"librosa==0.10.2.post1\" soundfile scipy pydub imageio-ffmpeg\n",
    "\n",
    "# TTS backends\n",
    "!pip install --quiet \"gTTS==2.5.3\" \"pyttsx3==2.90\"\n",
    "\n",
    "# OPTIONAL: Coqui XTTS v2 (very large download; comment out if you don't want it)\n",
    "!pip install --quiet TTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c279143-bd56-4a09-b6fe-a90300a74af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import math\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from langdetect import detect\n",
    "\n",
    "# File readers\n",
    "import PyPDF2\n",
    "from docx import Document as Docx\n",
    "from pptx import Presentation\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "from scipy.signal import butter, sosfilt\n",
    "from pydub import AudioSegment\n",
    "import imageio_ffmpeg\n",
    "\n",
    "# UI\n",
    "import gradio as gr\n",
    "\n",
    "# Configure pydub to use the bundled ffmpeg from imageio-ffmpeg\n",
    "AudioSegment.converter = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "# ---------------------------\n",
    "# TTS Backends (fail-soft)\n",
    "# ---------------------------\n",
    "_HAS_COQUI = False\n",
    "try:\n",
    "    # Only attempt to import Coqui if installed (it's optional & heavy)\n",
    "    from TTS.api import TTS as COQUI_TTS\n",
    "    _HAS_COQUI = True\n",
    "except Exception:\n",
    "    _HAS_COQUI = False\n",
    "\n",
    "try:\n",
    "    from gtts import gTTS\n",
    "    _HAS_GTTS = True\n",
    "except Exception:\n",
    "    _HAS_GTTS = False\n",
    "\n",
    "try:\n",
    "    import pyttsx3\n",
    "    _HAS_PYTT = True\n",
    "except Exception:\n",
    "    _HAS_PYTT = False\n",
    "\n",
    "# ---------------------------\n",
    "# Utility: Text Extraction\n",
    "# ---------------------------\n",
    "\n",
    "def extract_text(path: str) -> str:\n",
    "    ext = Path(path).suffix.lower()\n",
    "    if ext == \".pdf\":\n",
    "        with open(path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            pages = []\n",
    "            for i in range(len(reader.pages)):\n",
    "                try:\n",
    "                    pages.append(reader.pages[i].extract_text() or \"\")\n",
    "                except Exception:\n",
    "                    pages.append(\"\")\n",
    "            return \"\\n\\n\".join(pages)\n",
    "    elif ext in {\".doc\", \".docx\"}:\n",
    "        doc = Docx(path)\n",
    "        return \"\\n\".join(p.text for p in doc.paragraphs)\n",
    "    elif ext in {\".ppt\", \".pptx\"}:\n",
    "        prs = Presentation(path)\n",
    "        texts = []\n",
    "        for slide in prs.slides:\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"text\"):\n",
    "                    texts.append(shape.text)\n",
    "        return \"\\n\\n\".join(texts)\n",
    "    else:\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            return f.read()\n",
    "\n",
    "# ---------------------------\n",
    "# Utility: Chunking & Lang Detect\n",
    "# ---------------------------\n",
    "\n",
    "def chunk_text(text: str, max_chars: int = 400) -> list[str]:\n",
    "    raw_parts = [p.strip() for p in text.replace(\"\\r\", \"\\n\").split(\"\\n\") if p.strip()]\n",
    "    chunks = []\n",
    "    buf = []\n",
    "    total = 0\n",
    "    for part in raw_parts:\n",
    "        if total + len(part) + 1 > max_chars and buf:\n",
    "            chunks.append(\" \".join(buf))\n",
    "            buf, total = [], 0\n",
    "        buf.append(part)\n",
    "        total += len(part) + 1\n",
    "    if buf:\n",
    "        chunks.append(\" \".join(buf))\n",
    "    return chunks or ([text[:max_chars]] if text else [])\n",
    "\n",
    "def detect_lang_safe(text: str) -> str:\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except Exception:\n",
    "        return \"en\"\n",
    "\n",
    "# ---------------------------\n",
    "# Audio FX\n",
    "# ---------------------------\n",
    "def apply_gain_db(y: np.ndarray, db: float) -> np.ndarray:\n",
    "    factor = 10 ** (db / 20.0)\n",
    "    out = y * factor\n",
    "    maxv = np.max(np.abs(out)) if out.size else 0\n",
    "    if maxv > 1.0:\n",
    "        out = out / maxv * 0.99\n",
    "    return out.astype(np.float32)\n",
    "\n",
    "def apply_speed(y: np.ndarray, sr: int, speed: float) -> np.ndarray:\n",
    "    speed = max(0.25, min(2.0, float(speed)))\n",
    "    if speed == 1.0 or y.size == 0:\n",
    "        return y.astype(np.float32)\n",
    "    return librosa.effects.time_stretch(y, rate=speed).astype(np.float32)\n",
    "\n",
    "def apply_pitch(y: np.ndarray, sr: int, semitones: float) -> np.ndarray:\n",
    "    if semitones == 0 or y.size == 0:\n",
    "        return y.astype(np.float32)\n",
    "    return librosa.effects.pitch_shift(y, sr=sr, n_steps=semitones).astype(np.float32)\n",
    "\n",
    "def bandpass(y: np.ndarray, sr: int, center_hz: float, q: float = 1.0) -> np.ndarray:\n",
    "    if y.size == 0:\n",
    "        return y.astype(np.float32)\n",
    "    center_hz = float(np.clip(center_hz if center_hz else 1000.0, 20.0, min(20000.0, sr/2 - 100)))\n",
    "    q = max(0.1, float(q))\n",
    "    bw = center_hz / q\n",
    "    low = max(10.0, center_hz - bw/2)\n",
    "    high = min(sr/2 - 10.0, center_hz + bw/2)\n",
    "    if low >= high:\n",
    "        return y.astype(np.float32)\n",
    "    sos = butter(4, [low/(sr/2), high/(sr/2)], btype='bandpass', output='sos')\n",
    "    return sosfilt(sos, y).astype(np.float32)\n",
    "\n",
    "# ---------------------------\n",
    "# TTS: synthesize with graceful fallback\n",
    "# ---------------------------\n",
    "\n",
    "def _resample_if_needed(y: np.ndarray, sr_in: int, sr_out: int) -> np.ndarray:\n",
    "    if sr_in == sr_out:\n",
    "        return y.astype(np.float32)\n",
    "    return librosa.resample(y, orig_sr=sr_in, target_sr=sr_out, res_type=\"kaiser_best\").astype(np.float32)\n",
    "\n",
    "def _tts_coqui(text: str, lang_hint: str, sr: int) -> np.ndarray | None:\n",
    "    if not _HAS_COQUI:\n",
    "        return None\n",
    "    try:\n",
    "        # Multilingual XTTS v2 (heavy model; skip if not installed)\n",
    "        model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
    "        tts = COQUI_TTS(model_name)\n",
    "        lang = lang_hint if lang_hint in {\"en\", \"hi\"} else \"en\"\n",
    "        wav = tts.tts(text=text, language=lang)\n",
    "        y = np.array(wav, dtype=np.float32)\n",
    "        return _resample_if_needed(y, getattr(tts, \"synthesizer\", None).output_sample_rate if getattr(tts, \"synthesizer\", None) else 24000, sr)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _tts_gtts(text: str, lang_hint: str, sr: int) -> np.ndarray | None:\n",
    "    if not _HAS_GTTS:\n",
    "        return None\n",
    "    lang_map = {\"en\":\"en\", \"hi\":\"hi\", \"gu\":\"gu\"}\n",
    "    lang = lang_map.get(lang_hint, \"en\")\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as tmp:\n",
    "            gTTS(text=text, lang=lang).save(tmp.name)\n",
    "            seg = AudioSegment.from_file(tmp.name)\n",
    "        seg = seg.set_channels(1).set_frame_rate(sr)\n",
    "        samples = np.array(seg.get_array_of_samples()).astype(np.float32)\n",
    "        # Scale integer PCM to [-1,1]\n",
    "        y = samples / (2 ** (8 * seg.sample_width - 1))\n",
    "        return y.astype(np.float32)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _tts_pyttsx3(text: str, lang_hint: str, sr: int) -> np.ndarray | None:\n",
    "    if not _HAS_PYTT:\n",
    "        return None\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "        # Try to pick a voice matching the language; if not found, leave default\n",
    "        try:\n",
    "            for v in engine.getProperty('voices'):\n",
    "                langs = []\n",
    "                try:\n",
    "                    langs = [x.decode('utf-8') for x in v.languages] if v.languages else []\n",
    "                except Exception:\n",
    "                    langs = []\n",
    "                if lang_hint in \"\".join(langs) or lang_hint in str(v.id).lower():\n",
    "                    engine.setProperty('voice', v.id)\n",
    "                    break\n",
    "        except Exception:\n",
    "            pass\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "            out_path = tmp.name\n",
    "        engine.save_to_file(text, out_path)\n",
    "        engine.runAndWait()\n",
    "        y, sr_in = librosa.load(out_path, sr=sr, mono=True)\n",
    "        return y.astype(np.float32)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def synthesize_chunk(text: str, lang_hint: str, sr: int = 24000) -> np.ndarray:\n",
    "    # Try Coqui -> gTTS -> pyttsx3 -> silence\n",
    "    for fn in (_tts_coqui, _tts_gtts, _tts_pyttsx3):\n",
    "        y = fn(text, lang_hint, sr)\n",
    "        if y is not None and y.size > 0:\n",
    "            return y.astype(np.float32)\n",
    "    # Fallback: short silence to keep pipeline stable\n",
    "    return np.zeros(int(sr * 0.4), dtype=np.float32)\n",
    "\n",
    "def synthesize_text(text: str, sr: int = 24000) -> tuple[np.ndarray, int]:\n",
    "    chunks = chunk_text(text)\n",
    "    parts = []\n",
    "    for ch in chunks:\n",
    "        lang = detect_lang_safe(ch)\n",
    "        parts.append(synthesize_chunk(ch, lang, sr=sr))\n",
    "    if parts:\n",
    "        y = np.concatenate(parts).astype(np.float32)\n",
    "        peak = float(np.max(np.abs(y))) if y.size else 0.0\n",
    "        if peak > 0:\n",
    "            y = y / peak * 0.95\n",
    "    else:\n",
    "        y = np.zeros(int(sr * 0.5), dtype=np.float32)\n",
    "    return y.astype(np.float32), sr\n",
    "\n",
    "# ---------------------------\n",
    "# Session State\n",
    "# ---------------------------\n",
    "class Session:\n",
    "    def __init__(self):\n",
    "        self.y_full = np.zeros(0, dtype=np.float32)\n",
    "        self.sr = 24000\n",
    "        self.offset = 0.0\n",
    "        self.last_processed = (np.zeros(0, dtype=np.float32), 24000)\n",
    "\n",
    "    def load_text(self, text: str):\n",
    "        y, sr = synthesize_text(text)\n",
    "        self.y_full, self.sr = y, sr\n",
    "        self.offset = 0.0\n",
    "        self.last_processed = (y, sr)\n",
    "\n",
    "    def load_file(self, path: str):\n",
    "        text = extract_text(path)\n",
    "        self.load_text(text)\n",
    "\n",
    "    def process(self, speed=1.0, gain_db=-2.0, pitch_semitones=5.0, center_hz=3000.0, q=1.0):\n",
    "        y = self.y_full.copy()\n",
    "        if y.size == 0:\n",
    "            return np.zeros(0, dtype=np.float32), self.sr\n",
    "        # Sweet-girl preset baked in, but all sliders override it\n",
    "        if pitch_semitones:\n",
    "            y = apply_pitch(y, self.sr, float(pitch_semitones))\n",
    "        if speed and abs(float(speed) - 1.0) > 1e-6:\n",
    "            y = apply_speed(y, self.sr, float(speed))\n",
    "        if center_hz:\n",
    "            y = bandpass(y, self.sr, float(center_hz), float(q))\n",
    "        if gain_db:\n",
    "            y = apply_gain_db(y, float(gain_db))\n",
    "        self.last_processed = (y, self.sr)\n",
    "        return y, self.sr\n",
    "\n",
    "    def slice_from_offset(self, y: np.ndarray, sr: int) -> np.ndarray:\n",
    "        start = int(max(0.0, min(float(self.offset), len(y)/sr)) * sr)\n",
    "        return y[start:]\n",
    "\n",
    "    def save_wav(self, y: np.ndarray, sr: int) -> str:\n",
    "        fp = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "        sf.write(fp.name, y if y.size else np.zeros(1, dtype=np.float32), sr)\n",
    "        fp.flush()\n",
    "        return fp.name\n",
    "\n",
    "SESSION = Session()\n",
    "\n",
    "# ---------------------------\n",
    "# Gradio Callbacks\n",
    "# ---------------------------\n",
    "\n",
    "def ui_load_text(text):\n",
    "    text = text or \"\"\n",
    "    SESSION.load_text(text)\n",
    "    return \"Loaded text.\", \"\"\n",
    "\n",
    "def ui_load_file(file_path):\n",
    "    if not file_path:\n",
    "        return gr.update(), \"\"\n",
    "    SESSION.load_file(file_path)\n",
    "    return \"Loaded file.\", \"\"\n",
    "\n",
    "def ui_process(speed, gain_db, pitch_semitones, center_hz, wavelength, q):\n",
    "    # Keep wavelength & frequency in sync if wavelength was moved\n",
    "    try:\n",
    "        if wavelength is not None:\n",
    "            wavelength = float(wavelength)\n",
    "            wavelength = min(17.15, max(0.017, wavelength))\n",
    "            center_hz = 343.0 / wavelength\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    y, sr = SESSION.process(speed, gain_db, pitch_semitones, center_hz, q)\n",
    "    sliced = SESSION.slice_from_offset(y, sr)\n",
    "    wav_path = SESSION.save_wav(sliced, sr)\n",
    "    lam = 343.0 / max(1.0, float(center_hz or 1000.0))\n",
    "    return wav_path, f\"Offset: {SESSION.offset:.1f}s, Length: {len(sliced)/sr:.1f}s | λ≈{lam:.3f} m\"\n",
    "\n",
    "def ui_seek(delta):\n",
    "    SESSION.offset = max(0.0, float(SESSION.offset) + float(delta))\n",
    "    y, sr = SESSION.last_processed\n",
    "    sliced = SESSION.slice_from_offset(y, sr)\n",
    "    wav_path = SESSION.save_wav(sliced, sr)\n",
    "    return wav_path, f\"Offset: {SESSION.offset:.1f}s, Length: {len(sliced)/sr:.1f}s\"\n",
    "\n",
    "def ui_reset_offset():\n",
    "    SESSION.offset = 0.0\n",
    "    return ui_seek(0)\n",
    "\n",
    "# ---------------------------\n",
    "# Build Gradio Interface (Notebook-safe)\n",
    "# ---------------------------\n",
    "with gr.Blocks(title=\"Multilingual TTS Reader + Player\") as demo:\n",
    "    gr.Markdown(\n",
    "        \"# Multilingual TTS Reader + Player\\n\"\n",
    "        \"Default voice preset is a sweet girl's voice (Pitch +5, Tone 3000 Hz, Gain −2 dB). \"\n",
    "        \"Adjust any sliders to override.\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(label=\"Paste Text\", lines=6, placeholder=\"Paste text in Hindi / English / Gujarati...\")\n",
    "        file = gr.File(label=\"Or upload: PDF/DOCX/PPTX/TXT\", file_count=\"single\", type=\"filepath\")\n",
    "    with gr.Row():\n",
    "        load_text_btn = gr.Button(\"Load Text\")\n",
    "        load_file_btn = gr.Button(\"Load File\")\n",
    "        load_status = gr.Textbox(label=\"Loader Status\", interactive=False)\n",
    "\n",
    "    with gr.Row():\n",
    "        speed = gr.Slider(0.25, 2.0, value=1.0, step=0.05, label=\"Speed (x)\")\n",
    "        gain = gr.Slider(-30, 12, value=-2, step=1, label=\"Loudness / Gain (dB)\")\n",
    "        pitch = gr.Slider(-12, 12, value=5, step=0.5, label=\"Pitch Shift (semitones)\")\n",
    "    with gr.Row():\n",
    "        center = gr.Slider(20, 20000, value=3000, step=1, label=\"Tone Center Frequency (Hz)\")\n",
    "        wavelength = gr.Slider(0.017, 17.15, value=343.0/3000.0, step=0.001, label=\"Wavelength (m)\")\n",
    "        q = gr.Slider(0.2, 10.0, value=1.0, step=0.1, label=\"Tone Q (bandwidth)\")\n",
    "\n",
    "    process_btn = gr.Button(\"Process + Play from Offset\")\n",
    "    audio = gr.Audio(label=\"Audio Output\", interactive=False, type=\"filepath\", autoplay=True)\n",
    "    status = gr.Textbox(label=\"Playback Status\", interactive=False)\n",
    "\n",
    "    with gr.Row():\n",
    "        back10 = gr.Button(\"⏪ Rewind 10s\")\n",
    "        ahead10 = gr.Button(\"⏩ Forward 10s\")\n",
    "        reset = gr.Button(\"⏮️ Restart\")\n",
    "\n",
    "    # Events\n",
    "    load_text_btn.click(ui_load_text, inputs=[txt], outputs=[load_status, txt])\n",
    "    load_file_btn.click(ui_load_file, inputs=[file], outputs=[load_status, txt])\n",
    "    process_btn.click(ui_process, inputs=[speed, gain, pitch, center, wavelength, q], outputs=[audio, status])\n",
    "    back10.click(lambda: ui_seek(-10), outputs=[audio, status])\n",
    "    ahead10.click(lambda: ui_seek(10), outputs=[audio, status])\n",
    "    reset.click(ui_reset_offset, outputs=[audio, status])\n",
    "\n",
    "# In Jupyter, launch with:\n",
    "demo.launch(debug=False, share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a966761-eb9d-418e-a089-699a16a395b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
