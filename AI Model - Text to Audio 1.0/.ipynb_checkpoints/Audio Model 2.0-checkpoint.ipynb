{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083bab2-bec8-42d0-8851-410eb9a75f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multilingual Text-to-Speech (Hindi/English/Gujarati) + Player + Sweet Girl Preset + Logging\n",
    "------------------------------------------------------------------------------------------\n",
    "What this notebook/app does\n",
    "  • Reads text from: raw text, PDF, DOCX, PPTX, TXT (best-effort extraction)\n",
    "  • Detects language (Hindi/English/Gujarati) and synthesizes speech\n",
    "  • Default voice preset: “sweet girl” (pitch +5 semitones, tone center 3000 Hz, gain −2 dB)\n",
    "  • Player controls (via Gradio): Play, Rewind 10s, Forward 10s, Restart, Speed, Gain, Pitch, Frequency, Wavelength\n",
    "  • Wavelength <-> frequency linkage (λ = 343 / f)\n",
    "  • Saves output **MP3** by default (falls back to WAV if MP3 export fails) and logs each run\n",
    "  • Logging/Archival with auto-increment ID per item:\n",
    "      Textual Data/\n",
    "        ├── Hindi/\n",
    "        ├── English/\n",
    "        └── Gujarati/\n",
    "      Audio/\n",
    "        ├── Hindi/\n",
    "        ├── English/\n",
    "        └── Gujarati/\n",
    "      logs/session_log.csv\n",
    "\n",
    "\n",
    "#Installation (run in a Jupyter cell)\n",
    "#------------------------------------\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Core libraries\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install transformers\n",
    "!pip install gtts\n",
    "!pip install pydub\n",
    "!pip install librosa\n",
    "!pip install soundfile\n",
    "!pip install gradio\n",
    "!pip install langdetect\n",
    "!pip install python-docx\n",
    "!pip install python-pptx\n",
    "!pip install PyPDF2\n",
    "!pip install pandas\n",
    "\n",
    "# For MP3 export, you need FFmpeg available on your system PATH.\n",
    "# Linux (Debian/Ubuntu):  !apt-get update && apt-get install -y ffmpeg\n",
    "# Windows: install FFmpeg and add to PATH (https://ffmpeg.org/)\n",
    "# Mac:     brew install ffmpeg\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import io\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from langdetect import detect\n",
    "\n",
    "# File readers\n",
    "import PyPDF2\n",
    "from docx import Document as Docx\n",
    "from pptx import Presentation\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "from scipy.signal import butter, sosfilt\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# UI\n",
    "import gradio as gr\n",
    "\n",
    "# Optional: logs via pandas for convenience (not required for core)\n",
    "try:\n",
    "    import pandas as pd\n",
    "except Exception:\n",
    "    pd = None\n",
    "\n",
    "# ---------------------------\n",
    "# Config & Paths\n",
    "# ---------------------------\n",
    "SPEED_MIN, SPEED_MAX = 0.25, 2.0\n",
    "GAIN_MIN_DB, GAIN_MAX_DB = -30, 12\n",
    "PITCH_MIN, PITCH_MAX = -12, 12  # semitones\n",
    "FREQ_MIN_HZ, FREQ_MAX_HZ = 20, 20000\n",
    "WAVEL_MIN_M, WAVEL_MAX_M = 0.017, 17.15\n",
    "AIR_C = 343.0  # m/s\n",
    "\n",
    "DEFAULTS = {\n",
    "    \"speed\": 1.0,\n",
    "    \"gain_db\": -2.0,\n",
    "    \"pitch_semitones\": 5.0,  # sweet girl preset\n",
    "    \"center_hz\": 3000.0,\n",
    "    \"wavelength_m\": AIR_C / 3000.0,\n",
    "    \"q\": 1.0,\n",
    "    \"sr\": 24000,\n",
    "}\n",
    "\n",
    "BASE_TEXT_DIR = Path(\"Textual Data\")\n",
    "BASE_AUDIO_DIR = Path(\"Audio\")\n",
    "LOGS_DIR = Path(\"logs\")\n",
    "LOG_CSV = LOGS_DIR / \"session_log.csv\"\n",
    "\n",
    "LANG_MAP = {\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"en\": \"English\",\n",
    "    \"gu\": \"Gujarati\",\n",
    "}\n",
    "\n",
    "# Ensure directories\n",
    "for root in [BASE_TEXT_DIR, BASE_AUDIO_DIR, LOGS_DIR]:\n",
    "    root.mkdir(parents=True, exist_ok=True)\n",
    "for lang_name in [\"Hindi\", \"English\", \"Gujarati\"]:\n",
    "    (BASE_TEXT_DIR / lang_name).mkdir(parents=True, exist_ok=True)\n",
    "    (BASE_AUDIO_DIR / lang_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Utility: Text Extraction\n",
    "# ---------------------------\n",
    "\n",
    "def extract_text(path: str) -> str:\n",
    "    ext = Path(path).suffix.lower()\n",
    "    if ext == \".pdf\":\n",
    "        with open(path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            pages = []\n",
    "            for i in range(len(reader.pages)):\n",
    "                try:\n",
    "                    pages.append(reader.pages[i].extract_text() or \"\")\n",
    "                except Exception:\n",
    "                    pages.append(\"\")\n",
    "            return \"\\n\\n\".join(pages)\n",
    "    elif ext in {\".doc\", \".docx\"}:\n",
    "        doc = Docx(path)\n",
    "        return \"\\n\".join(p.text for p in doc.paragraphs)\n",
    "    elif ext in {\".ppt\", \".pptx\"}:\n",
    "        prs = Presentation(path)\n",
    "        texts = []\n",
    "        for slide in prs.slides:\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"text\"):\n",
    "                    texts.append(shape.text)\n",
    "        return \"\\n\\n\".join(texts)\n",
    "    else:\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            return f.read()\n",
    "\n",
    "# ---------------------------\n",
    "# Utility: Chunking & Lang Detect\n",
    "# ---------------------------\n",
    "\n",
    "def chunk_text(text: str, max_chars: int = 400) -> list[str]:\n",
    "    raw_parts = [p.strip() for p in text.replace(\"\\r\", \"\\n\").split(\"\\n\") if p.strip()]\n",
    "    chunks = []\n",
    "    buf = []\n",
    "    total = 0\n",
    "    for part in raw_parts:\n",
    "        if total + len(part) + 1 > max_chars and buf:\n",
    "            chunks.append(\" \".join(buf))\n",
    "            buf, total = [], 0\n",
    "        buf.append(part)\n",
    "        total += len(part) + 1\n",
    "    if buf:\n",
    "        chunks.append(\" \".join(buf))\n",
    "    return chunks or ([text[:max_chars]] if text else [])\n",
    "\n",
    "\n",
    "def detect_lang_safe(text: str) -> str:\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except Exception:\n",
    "        return \"en\"\n",
    "\n",
    "# ---------------------------\n",
    "# TTS Backends\n",
    "# ---------------------------\n",
    "try:\n",
    "    from TTS.api import TTS as COQUI_TTS\n",
    "    _HAS_COQUI = True\n",
    "except Exception:\n",
    "    _HAS_COQUI = False\n",
    "\n",
    "try:\n",
    "    from gtts import gTTS\n",
    "    _HAS_GTTS = True\n",
    "except Exception:\n",
    "    _HAS_GTTS = False\n",
    "\n",
    "try:\n",
    "    import pyttsx3\n",
    "    _HAS_PYTT = True\n",
    "except Exception:\n",
    "    _HAS_PYTT = False\n",
    "\n",
    "\n",
    "def synthesize_chunk(text: str, lang_hint: str, sr: int = DEFAULTS[\"sr\"]) -> np.ndarray:\n",
    "    lang = lang_hint\n",
    "    if _HAS_COQUI:\n",
    "        try:\n",
    "            model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
    "            tts = COQUI_TTS(model_name)\n",
    "            wav = tts.tts(text=text, language=lang if lang in {\"en\", \"hi\"} else \"en\")\n",
    "            y = np.array(wav, dtype=np.float32)\n",
    "            if sr != tts.synthesizer.output_sample_rate:\n",
    "                y = librosa.resample(y, orig_sr=tts.synthesizer.output_sample_rate, target_sr=sr)\n",
    "            return y.astype(np.float32)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if _HAS_GTTS and lang in {\"en\", \"hi\", \"gu\"}:\n",
    "        try:\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as tmp:\n",
    "                gTTS(text=text, lang=lang).save(tmp.name)\n",
    "                seg = AudioSegment.from_file(tmp.name)\n",
    "                seg = seg.set_channels(1).set_frame_rate(sr)\n",
    "                samples = np.array(seg.get_array_of_samples()).astype(np.float32)\n",
    "                y = samples / (2 ** (8 * seg.sample_width - 1))\n",
    "                return y\n",
    "        except Exception:\n",
    "            pass\n",
    "    if _HAS_PYTT:\n",
    "        try:\n",
    "            engine = pyttsx3.init()\n",
    "            for v in engine.getProperty('voices'):\n",
    "                if lang in (v.languages[0].decode('utf-8') if v.languages else str(v.id)):\n",
    "                    engine.setProperty('voice', v.id)\n",
    "                    break\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "                out_path = tmp.name\n",
    "            engine.save_to_file(text, out_path)\n",
    "            engine.runAndWait()\n",
    "            y, sr_in = librosa.load(out_path, sr=sr, mono=True)\n",
    "            return y.astype(np.float32)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return np.zeros(int(sr * 0.5), dtype=np.float32)\n",
    "\n",
    "\n",
    "def synthesize_text(text: str, sr: int = DEFAULTS[\"sr\"]) -> tuple[np.ndarray, int]:\n",
    "    chunks = chunk_text(text)\n",
    "    parts = []\n",
    "    for ch in chunks:\n",
    "        lang = detect_lang_safe(ch)\n",
    "        parts.append(synthesize_chunk(ch, lang, sr=sr))\n",
    "    y = np.concatenate(parts) if parts else np.zeros(int(sr * 0.5), dtype=np.float32)\n",
    "    peak = np.max(np.abs(y)) or 1.0\n",
    "    y = y / peak * 0.95\n",
    "    return y.astype(np.float32), sr\n",
    "\n",
    "# ---------------------------\n",
    "# Audio FX\n",
    "# ---------------------------\n",
    "\n",
    "def apply_gain_db(y: np.ndarray, db: float) -> np.ndarray:\n",
    "    factor = 10 ** (db / 20.0)\n",
    "    out = y * factor\n",
    "    maxv = np.max(np.abs(out))\n",
    "    if maxv > 1.0:\n",
    "        out = out / maxv * 0.99\n",
    "    return out.astype(np.float32)\n",
    "\n",
    "\n",
    "def apply_speed(y: np.ndarray, sr: int, speed: float) -> np.ndarray:\n",
    "    speed = max(SPEED_MIN, min(SPEED_MAX, float(speed)))\n",
    "    return librosa.effects.time_stretch(y, rate=speed).astype(np.float32)\n",
    "\n",
    "\n",
    "def apply_pitch(y: np.ndarray, sr: int, semitones: float) -> np.ndarray:\n",
    "    semitones = max(PITCH_MIN, min(PITCH_MAX, float(semitones)))\n",
    "    return librosa.effects.pitch_shift(y, sr=sr, n_steps=semitones).astype(np.float32)\n",
    "\n",
    "\n",
    "def bandpass(y: np.ndarray, sr: int, center_hz: float, q: float = 1.0) -> np.ndarray:\n",
    "    center_hz = float(np.clip(center_hz, FREQ_MIN_HZ, min(FREQ_MAX_HZ, sr/2 - 100)))\n",
    "    bw = center_hz / max(q, 0.1)\n",
    "    low = max(10.0, center_hz - bw/2)\n",
    "    high = min(sr/2 - 10.0, center_hz + bw/2)\n",
    "    if low >= high:\n",
    "        return y\n",
    "    sos = butter(4, [low/(sr/2), high/(sr/2)], btype='bandpass', output='sos')\n",
    "    return sosfilt(sos, y).astype(np.float32)\n",
    "\n",
    "# ---------------------------\n",
    "# Logging & ID helpers\n",
    "# ---------------------------\n",
    "\n",
    "def next_id() -> str:\n",
    "    \"\"\"Compute next zero-padded ID based on session_log.csv (6 digits).\"\"\"\n",
    "    LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    if not LOG_CSV.exists():\n",
    "        return \"000001\"\n",
    "    try:\n",
    "        with open(LOG_CSV, newline='', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            max_id = 0\n",
    "            for row in reader:\n",
    "                try:\n",
    "                    max_id = max(max_id, int(row.get('ID', 0)))\n",
    "                except Exception:\n",
    "                    pass\n",
    "        return f\"{max_id+1:06d}\"\n",
    "    except Exception:\n",
    "        return \"000001\"\n",
    "\n",
    "\n",
    "def write_log_row(row: dict):\n",
    "    headers = [\"ID\", \"Language\", \"InputSource\", \"Timestamp\", \"TextFilePath\", \"AudioFilePath\", \"Speed\", \"GainDB\", \"PitchSemitones\", \"CenterHz\", \"WavelengthM\", \"Q\"]\n",
    "    new_file = not LOG_CSV.exists()\n",
    "    with open(LOG_CSV, \"a\", newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=headers)\n",
    "        if new_file:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "def save_text_and_audio(id_str: str, language_name: str, text: str, y: np.ndarray, sr: int, prefer_mp3: bool = True) -> tuple[Path, Path, str]:\n",
    "    # Save text\n",
    "    text_dir = BASE_TEXT_DIR / language_name\n",
    "    audio_dir = BASE_AUDIO_DIR / language_name\n",
    "    text_dir.mkdir(parents=True, exist_ok=True)\n",
    "    audio_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    txt_path = text_dir / f\"{id_str}.txt\"\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "    # Save audio as WAV temp first, then convert to MP3 if possible\n",
    "    wav_tmp = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "    sf.write(wav_tmp.name, y, sr)\n",
    "    wav_tmp.flush()\n",
    "\n",
    "    audio_path = None\n",
    "    used_format = \"wav\"\n",
    "\n",
    "    if prefer_mp3:\n",
    "        try:\n",
    "            seg = AudioSegment.from_file(wav_tmp.name)\n",
    "            audio_path = audio_dir / f\"{id_str}.mp3\"\n",
    "            seg.export(str(audio_path), format=\"mp3\", bitrate=\"192k\")\n",
    "            used_format = \"mp3\"\n",
    "        except Exception:\n",
    "            # fallback to WAV\n",
    "            audio_path = audio_dir / f\"{id_str}.wav\"\n",
    "            sf.write(str(audio_path), y, sr)\n",
    "            used_format = \"wav\"\n",
    "    else:\n",
    "        audio_path = audio_dir / f\"{id_str}.wav\"\n",
    "        sf.write(str(audio_path), y, sr)\n",
    "        used_format = \"wav\"\n",
    "\n",
    "    try:\n",
    "        os.unlink(wav_tmp.name)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return txt_path, audio_path, used_format\n",
    "\n",
    "# ---------------------------\n",
    "# Session State\n",
    "# ---------------------------\n",
    "class Session:\n",
    "    def __init__(self):\n",
    "        self.y_full = None\n",
    "        self.sr = DEFAULTS[\"sr\"]\n",
    "        self.offset = 0.0\n",
    "        self.last_processed = None\n",
    "        self.last_text = \"\"\n",
    "        self.last_language = \"English\"\n",
    "        self.last_id = None\n",
    "        self.last_saved_audio_path = None\n",
    "        self.last_saved_text_path = None\n",
    "\n",
    "    def detect_language_name(self, text: str) -> str:\n",
    "        code = detect_lang_safe(text or \"\")\n",
    "        return LANG_MAP.get(code, \"English\")\n",
    "\n",
    "    def load_text(self, text: str):\n",
    "        self.last_text = text or \"\"\n",
    "        self.last_language = self.detect_language_name(self.last_text[:400])\n",
    "        y, sr = synthesize_text(self.last_text, sr=self.sr)\n",
    "        self.y_full, self.sr = y, sr\n",
    "        self.offset = 0.0\n",
    "        self.last_processed = None\n",
    "\n",
    "    def load_file(self, path: str):\n",
    "        text = extract_text(path)\n",
    "        self.load_text(text)\n",
    "\n",
    "    def process(self, speed=DEFAULTS[\"speed\"], gain_db=DEFAULTS[\"gain_db\"], pitch_semitones=DEFAULTS[\"pitch_semitones\"], center_hz=DEFAULTS[\"center_hz\"], q=DEFAULTS[\"q\"]):\n",
    "        if self.y_full is None:\n",
    "            return None, None\n",
    "        y = self.y_full.copy()\n",
    "        # Order: pitch -> speed -> tone -> gain\n",
    "        if pitch_semitones:\n",
    "            y = apply_pitch(y, self.sr, pitch_semitones)\n",
    "        if speed and abs(speed - 1.0) > 1e-3:\n",
    "            y = apply_speed(y, self.sr, speed)\n",
    "        if center_hz:\n",
    "            y = bandpass(y, self.sr, center_hz, q)\n",
    "        if gain_db:\n",
    "            y = apply_gain_db(y, gain_db)\n",
    "        self.last_processed = (y, self.sr)\n",
    "        return y, self.sr\n",
    "\n",
    "    def slice_from_offset(self, y: np.ndarray, sr: int) -> np.ndarray:\n",
    "        start = int(self.offset * sr)\n",
    "        start = max(0, min(start, len(y)))\n",
    "        return y[start:]\n",
    "\n",
    "    def save_run(self, y: np.ndarray, sr: int, freq_hz: float, wavelength_m: float, speed: float, gain_db: float, pitch_semitones: float, q: float, input_source: str = \"typed\", prefer_mp3: bool = True) -> tuple[str, Path, Path, str]:\n",
    "        id_str = next_id()\n",
    "        txt_path, audio_path, fmt = save_text_and_audio(id_str, self.last_language, self.last_text, y, sr, prefer_mp3=prefer_mp3)\n",
    "        timestamp = datetime.utcnow().isoformat()\n",
    "        write_log_row({\n",
    "            \"ID\": id_str,\n",
    "            \"Language\": self.last_language,\n",
    "            \"InputSource\": input_source,\n",
    "            \"Timestamp\": timestamp,\n",
    "            \"TextFilePath\": str(txt_path),\n",
    "            \"AudioFilePath\": str(audio_path),\n",
    "            \"Speed\": speed,\n",
    "            \"GainDB\": gain_db,\n",
    "            \"PitchSemitones\": pitch_semitones,\n",
    "            \"CenterHz\": round(freq_hz, 3),\n",
    "            \"WavelengthM\": round(wavelength_m, 5),\n",
    "            \"Q\": q,\n",
    "        })\n",
    "        self.last_id = id_str\n",
    "        self.last_saved_audio_path = audio_path\n",
    "        self.last_saved_text_path = txt_path\n",
    "        return id_str, txt_path, audio_path, fmt\n",
    "\n",
    "SESSION = Session()\n",
    "\n",
    "# ---------------------------\n",
    "# Gradio Callbacks\n",
    "# ---------------------------\n",
    "\n",
    "def ui_load_text(text):\n",
    "    SESSION.load_text(text)\n",
    "    return gr.update(value=f\"Loaded text. Language: {SESSION.last_language}\"), \"\"\n",
    "\n",
    "\n",
    "def ui_load_file(file):\n",
    "    if file is None:\n",
    "        return gr.update(), \"\"\n",
    "    SESSION.load_file(file.name)\n",
    "    return gr.update(value=f\"Loaded file. Language: {SESSION.last_language}\"), SESSION.last_text[:500]\n",
    "\n",
    "\n",
    "def ui_process(speed, gain_db, pitch_semitones, center_hz, wavelength, q):\n",
    "    # Wavelength <-> Frequency synchronization\n",
    "    if wavelength is not None:\n",
    "        wavelength = float(max(WAVEL_MIN_M, min(WAVEL_MAX_M, float(wavelength))))\n",
    "        center_hz = AIR_C / wavelength\n",
    "    center_hz = float(max(FREQ_MIN_HZ, min(FREQ_MAX_HZ, float(center_hz))))\n",
    "\n",
    "    y, sr = SESSION.process(speed, gain_db, pitch_semitones, center_hz, q)\n",
    "    if y is None:\n",
    "        return None, \"No audio yet.\", \"\"\n",
    "\n",
    "    # Playback slice from current offset\n",
    "    sliced = SESSION.slice_from_offset(y, sr)\n",
    "    play_wav_path = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False).name\n",
    "    sf.write(play_wav_path, sliced, sr)\n",
    "\n",
    "    # Save FULL processed audio + text with auto-increment ID (archive/log)\n",
    "    full_id, txt_path, audio_path, fmt = SESSION.save_run(y, sr, center_hz, AIR_C / center_hz, speed, gain_db, pitch_semitones, q, input_source=\"typed\", prefer_mp3=True)\n",
    "\n",
    "    status = (f\"Saved ID #{full_id} | Lang: {SESSION.last_language} | File: {audio_path.name} ({fmt.upper()})\\n\"\n",
    "              f\"Text → {txt_path}\\nAudio → {audio_path}\\n\"\n",
    "              f\"Offset: {SESSION.offset:.1f}s | Play length: {len(sliced)/sr:.1f}s | λ≈{AIR_C/center_hz:.3f} m\")\n",
    "    return play_wav_path, status, str(audio_path)\n",
    "\n",
    "\n",
    "def ui_seek(delta):\n",
    "    SESSION.offset = max(0.0, SESSION.offset + float(delta))\n",
    "    if SESSION.last_processed is None:\n",
    "        return None, f\"Offset: {SESSION.offset:.1f}s\"\n",
    "    y, sr = SESSION.last_processed\n",
    "    sliced = SESSION.slice_from_offset(y, sr)\n",
    "    wav_path = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False).name\n",
    "    sf.write(wav_path, sliced, sr)\n",
    "    return wav_path, f\"Offset: {SESSION.offset:.1f}s, Play length: {len(sliced)/sr:.1f}s\"\n",
    "\n",
    "\n",
    "def ui_reset_offset():\n",
    "    SESSION.offset = 0.0\n",
    "    return ui_seek(0)\n",
    "\n",
    "# ---------------------------\n",
    "# Build Gradio Interface\n",
    "# ---------------------------\n",
    "with gr.Blocks(title=\"Multilingual TTS Reader + Player + Logging\") as demo:\n",
    "    gr.Markdown(\"# Multilingual TTS Reader + Player + Logging\\nDefault preset: **sweet girl's voice** (Pitch +5, Tone 3 kHz, Gain −2 dB). Adjust any slider to override.\\n\\n**Note:** Audible/safe ranges enforced. For MP3 export, FFmpeg must be installed.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(label=\"Paste Text\", lines=6, placeholder=\"Type or paste Hindi / English / Gujarati / mixed text…\")\n",
    "        file = gr.File(file_types=[\".pdf\", \".docx\", \".pptx\", \".txt\"], label=\"Or upload: PDF / DOCX / PPTX / TXT\")\n",
    "    with gr.Row():\n",
    "        load_text_btn = gr.Button(\"Load Text\")\n",
    "        load_file_btn = gr.Button(\"Load File\")\n",
    "        load_status = gr.Textbox(label=\"Loader Status\", interactive=False)\n",
    "\n",
    "    with gr.Row():\n",
    "        speed = gr.Slider(SPEED_MIN, SPEED_MAX, value=DEFAULTS[\"speed\"], step=0.05, label=\"Speed (x)\")\n",
    "        gain = gr.Slider(GAIN_MIN_DB, GAIN_MAX_DB, value=DEFAULTS[\"gain_db\"], step=1, label=\"Loudness / Gain (dB)\")\n",
    "        pitch = gr.Slider(PITCH_MIN, PITCH_MAX, value=DEFAULTS[\"pitch_semitones\"], step=0.5, label=\"Pitch Shift (semitones)\")\n",
    "    with gr.Row():\n",
    "        center = gr.Slider(FREQ_MIN_HZ, FREQ_MAX_HZ, value=DEFAULTS[\"center_hz\"], step=1, label=\"Tone Center Frequency (Hz)\")\n",
    "        wavelength = gr.Slider(WAVEL_MIN_M, WAVEL_MAX_M, value=DEFAULTS[\"wavelength_m\"], step=0.001, label=\"Wavelength (m)\")\n",
    "        q = gr.Slider(0.2, 10.0, value=DEFAULTS[\"q\"], step=0.1, label=\"Tone Q (bandwidth)\")\n",
    "\n",
    "    process_btn = gr.Button(\"Process + Save + Play from Offset\")\n",
    "    audio = gr.Audio(label=\"Audio Output\", interactive=False)\n",
    "    status = gr.Textbox(label=\"Status & Saved Paths\", interactive=False)\n",
    "    last_audio_path = gr.Textbox(label=\"Last Saved Audio Path\", interactive=False)\n",
    "\n",
    "    with gr.Row():\n",
    "        back10 = gr.Button(\"⏪ Rewind 10s\")\n",
    "        ahead10 = gr.Button(\"⏩ Forward 10s\")\n",
    "        reset = gr.Button(\"⏮️ Restart\")\n",
    "\n",
    "    # Events\n",
    "    load_text_btn.click(ui_load_text, inputs=[txt], outputs=[load_status, txt])\n",
    "    load_file_btn.click(ui_load_file, inputs=[file], outputs=[load_status, txt])\n",
    "    process_btn.click(ui_process, inputs=[speed, gain, pitch, center, wavelength, q], outputs=[audio, status, last_audio_path])\n",
    "    back10.click(lambda: ui_seek(-10), outputs=[audio, status])\n",
    "    ahead10.click(lambda: ui_seek(10), outputs=[audio, status])\n",
    "    reset.click(ui_reset_offset, outputs=[audio, status])\n",
    "\n",
    "# In Jupyter, run:\n",
    "demo.launch(debug=False, share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bade67-35e8-4d3c-bc95-8fc5a49278de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
