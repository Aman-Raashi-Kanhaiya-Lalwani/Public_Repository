{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c279143-bd56-4a09-b6fe-a90300a74af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 0.0.10.2 Requires-Python >=3.6.0, <3.9; 0.0.10.3 Requires-Python >=3.6.0, <3.9; 0.0.11 Requires-Python >=3.6.0, <3.9; 0.0.12 Requires-Python >=3.6.0, <3.9; 0.0.13.1 Requires-Python >=3.6.0, <3.9; 0.0.13.2 Requires-Python >=3.6.0, <3.9; 0.0.14.1 Requires-Python >=3.6.0, <3.9; 0.0.15 Requires-Python >=3.6.0, <3.9; 0.0.15.1 Requires-Python >=3.6.0, <3.9; 0.0.9 Requires-Python >=3.6.0, <3.9; 0.0.9.1 Requires-Python >=3.6.0, <3.9; 0.0.9.2 Requires-Python >=3.6.0, <3.9; 0.0.9a10 Requires-Python >=3.6.0, <3.9; 0.0.9a9 Requires-Python >=3.6.0, <3.9; 0.1.0 Requires-Python >=3.6.0, <3.10; 0.1.1 Requires-Python >=3.6.0, <3.10; 0.1.2 Requires-Python >=3.6.0, <3.10; 0.1.3 Requires-Python >=3.6.0, <3.10; 0.10.0 Requires-Python >=3.7.0, <3.11; 0.10.1 Requires-Python >=3.7.0, <3.11; 0.10.2 Requires-Python >=3.7.0, <3.11; 0.11.0 Requires-Python >=3.7.0, <3.11; 0.11.1 Requires-Python >=3.7.0, <3.11; 0.12.0 Requires-Python >=3.7.0, <3.11; 0.13.0 Requires-Python >=3.7.0, <3.11; 0.13.1 Requires-Python >=3.7.0, <3.11; 0.13.2 Requires-Python >=3.7.0, <3.11; 0.13.3 Requires-Python >=3.7.0, <3.11; 0.14.0 Requires-Python >=3.7.0, <3.11; 0.14.2 Requires-Python >=3.7.0, <3.11; 0.14.3 Requires-Python >=3.7.0, <3.11; 0.15.0 Requires-Python >=3.9.0, <3.12; 0.15.1 Requires-Python >=3.9.0, <3.12; 0.15.2 Requires-Python >=3.9.0, <3.12; 0.15.4 Requires-Python >=3.9.0, <3.12; 0.15.5 Requires-Python >=3.9.0, <3.12; 0.15.6 Requires-Python >=3.9.0, <3.12; 0.16.0 Requires-Python >=3.9.0, <3.12; 0.16.1 Requires-Python >=3.9.0, <3.12; 0.16.3 Requires-Python >=3.9.0, <3.12; 0.16.4 Requires-Python >=3.9.0, <3.12; 0.16.5 Requires-Python >=3.9.0, <3.12; 0.16.6 Requires-Python >=3.9.0, <3.12; 0.17.0 Requires-Python >=3.9.0, <3.12; 0.17.1 Requires-Python >=3.9.0, <3.12; 0.17.2 Requires-Python >=3.9.0, <3.12; 0.17.4 Requires-Python >=3.9.0, <3.12; 0.17.5 Requires-Python >=3.9.0, <3.12; 0.17.6 Requires-Python >=3.9.0, <3.12; 0.17.7 Requires-Python >=3.9.0, <3.12; 0.17.8 Requires-Python >=3.9.0, <3.12; 0.17.9 Requires-Python >=3.9.0, <3.12; 0.18.0 Requires-Python >=3.9.0, <3.12; 0.18.1 Requires-Python >=3.9.0, <3.12; 0.18.2 Requires-Python >=3.9.0, <3.12; 0.19.0 Requires-Python >=3.9.0, <3.12; 0.19.1 Requires-Python >=3.9.0, <3.12; 0.2.0 Requires-Python >=3.6.0, <3.10; 0.2.1 Requires-Python >=3.6.0, <3.10; 0.2.2 Requires-Python >=3.6.0, <3.10; 0.20.0 Requires-Python >=3.9.0, <3.12; 0.20.1 Requires-Python >=3.9.0, <3.12; 0.20.2 Requires-Python >=3.9.0, <3.12; 0.20.3 Requires-Python >=3.9.0, <3.12; 0.20.4 Requires-Python >=3.9.0, <3.12; 0.20.5 Requires-Python >=3.9.0, <3.12; 0.20.6 Requires-Python >=3.9.0, <3.12; 0.21.0 Requires-Python >=3.9.0, <3.12; 0.21.1 Requires-Python >=3.9.0, <3.12; 0.21.2 Requires-Python >=3.9.0, <3.12; 0.21.3 Requires-Python >=3.9.0, <3.12; 0.22.0 Requires-Python >=3.9.0, <3.12; 0.3.0 Requires-Python >=3.6.0, <3.10; 0.3.1 Requires-Python >=3.6.0, <3.10; 0.4.0 Requires-Python >=3.6.0, <3.10; 0.4.1 Requires-Python >=3.6.0, <3.10; 0.4.2 Requires-Python >=3.6.0, <3.10; 0.5.0 Requires-Python >=3.6.0, <3.10; 0.6.0 Requires-Python >=3.6.0, <3.10; 0.6.1 Requires-Python >=3.6.0, <3.10; 0.6.2 Requires-Python >=3.6.0, <3.10; 0.7.0 Requires-Python >=3.7.0, <3.11; 0.7.1 Requires-Python >=3.7.0, <3.11; 0.8.0 Requires-Python >=3.7.0, <3.11; 0.9.0 Requires-Python >=3.7.0, <3.11\n",
      "ERROR: Could not find a version that satisfies the requirement TTS (from versions: none)\n",
      "ERROR: No matching distribution found for TTS\n",
      "C:\\Users\\amanl\\anaconda3\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "C:\\Users\\amanl\\anaconda3\\Lib\\site-packages\\gradio\\analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Multilingual Text-to-Speech (Hindi/English/Gujarati) + Player Controls + Sweet Girl Preset\n",
    "----------------------------------------------------------------------------------------\n",
    "Features:\n",
    "  • Reads text from raw text, PDF, DOCX, PPTX\n",
    "  • Detects language (Hindi/English/Gujarati) and synthesizes speech\n",
    "  • Default voice preset: “sweet girl” voice (pitch +5 semitones, tone center 3000 Hz, soft gain)\n",
    "  • UI controls with scrollbars:\n",
    "      - Play/Pause\n",
    "      - Rewind / Fast-forward 10s\n",
    "      - Speed control (0.25x–2.0x + custom)\n",
    "      - Loudness (Gain −30 … +12 dB)\n",
    "      - Pitch shift (−12 … +12 semitones)\n",
    "      - Frequency slider (20–20,000 Hz)\n",
    "      - Wavelength slider (0.017–17 m, linked to frequency)\n",
    "  • Displays current wavelength for chosen frequency\n",
    "  • Saves output as WAV for playback/download\n",
    "\"\"\"\n",
    "# Install dependencies (run in a notebook cell):\n",
    "# ------------------------------------------------\n",
    "!pip install --quiet gradio==4.44.0 langdetect PyPDF2 python-docx python-pptx pydub librosa soundfile scipy numpy\n",
    "!pip install --quiet TTS gTTS pyttsx3\n",
    "\n",
    "\n",
    "import os\n",
    "import io\n",
    "import math\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from langdetect import detect\n",
    "\n",
    "# File readers\n",
    "import PyPDF2\n",
    "from docx import Document as Docx\n",
    "from pptx import Presentation\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "from scipy.signal import butter, sosfilt\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# UI\n",
    "import gradio as gr\n",
    "\n",
    "# ---------------------------\n",
    "# Utility: Text Extraction\n",
    "# ---------------------------\n",
    "\n",
    "def extract_text(path: str) -> str:\n",
    "    ext = Path(path).suffix.lower()\n",
    "    if ext == \".pdf\":\n",
    "        with open(path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            pages = []\n",
    "            for i in range(len(reader.pages)):\n",
    "                try:\n",
    "                    pages.append(reader.pages[i].extract_text() or \"\")\n",
    "                except Exception:\n",
    "                    pages.append(\"\")\n",
    "            return \"\\n\\n\".join(pages)\n",
    "    elif ext in {\".doc\", \".docx\"}:\n",
    "        doc = Docx(path)\n",
    "        return \"\\n\".join(p.text for p in doc.paragraphs)\n",
    "    elif ext in {\".ppt\", \".pptx\"}:\n",
    "        prs = Presentation(path)\n",
    "        texts = []\n",
    "        for slide in prs.slides:\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"text\"):\n",
    "                    texts.append(shape.text)\n",
    "        return \"\\n\\n\".join(texts)\n",
    "    else:\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            return f.read()\n",
    "\n",
    "# ---------------------------\n",
    "# Utility: Chunking & Lang Detect\n",
    "# ---------------------------\n",
    "\n",
    "def chunk_text(text: str, max_chars: int = 400) -> list[str]:\n",
    "    raw_parts = [p.strip() for p in text.replace(\"\\r\", \"\\n\").split(\"\\n\") if p.strip()]\n",
    "    chunks = []\n",
    "    buf = []\n",
    "    total = 0\n",
    "    for part in raw_parts:\n",
    "        if total + len(part) + 1 > max_chars and buf:\n",
    "            chunks.append(\" \".join(buf))\n",
    "            buf, total = [], 0\n",
    "        buf.append(part)\n",
    "        total += len(part) + 1\n",
    "    if buf:\n",
    "        chunks.append(\" \".join(buf))\n",
    "    return chunks or ([text[:max_chars]] if text else [])\n",
    "\n",
    "\n",
    "def detect_lang_safe(text: str) -> str:\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except Exception:\n",
    "        return \"en\"\n",
    "\n",
    "# ---------------------------\n",
    "# TTS Backends\n",
    "# ---------------------------\n",
    "try:\n",
    "    from TTS.api import TTS as COQUI_TTS\n",
    "    _HAS_COQUI = True\n",
    "except Exception:\n",
    "    _HAS_COQUI = False\n",
    "\n",
    "try:\n",
    "    from gtts import gTTS\n",
    "    _HAS_GTTS = True\n",
    "except Exception:\n",
    "    _HAS_GTTS = False\n",
    "\n",
    "try:\n",
    "    import pyttsx3\n",
    "    _HAS_PYTT = True\n",
    "except Exception:\n",
    "    _HAS_PYTT = False\n",
    "\n",
    "\n",
    "def synthesize_chunk(text: str, lang_hint: str, sr: int = 24000) -> np.ndarray:\n",
    "    lang = lang_hint\n",
    "    if _HAS_COQUI:\n",
    "        try:\n",
    "            model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
    "            tts = COQUI_TTS(model_name)\n",
    "            wav = tts.tts(text=text, language=lang if lang in {\"en\", \"hi\"} else \"en\")\n",
    "            y = np.array(wav, dtype=np.float32)\n",
    "            if sr != tts.synthesizer.output_sample_rate:\n",
    "                y = librosa.resample(y, orig_sr=tts.synthesizer.output_sample_rate, target_sr=sr)\n",
    "            return y.astype(np.float32)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if _HAS_GTTS and lang in {\"en\", \"hi\", \"gu\"}:\n",
    "        try:\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as tmp:\n",
    "                gTTS(text=text, lang=lang).save(tmp.name)\n",
    "                seg = AudioSegment.from_file(tmp.name)\n",
    "                seg = seg.set_channels(1).set_frame_rate(sr)\n",
    "                samples = np.array(seg.get_array_of_samples()).astype(np.float32)\n",
    "                y = samples / (2 ** (8 * seg.sample_width - 1))\n",
    "                return y\n",
    "        except Exception:\n",
    "            pass\n",
    "    if _HAS_PYTT:\n",
    "        try:\n",
    "            engine = pyttsx3.init()\n",
    "            for v in engine.getProperty('voices'):\n",
    "                if lang in (v.languages[0].decode('utf-8') if v.languages else str(v.id)):\n",
    "                    engine.setProperty('voice', v.id)\n",
    "                    break\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "                out_path = tmp.name\n",
    "            engine.save_to_file(text, out_path)\n",
    "            engine.runAndWait()\n",
    "            y, sr_in = librosa.load(out_path, sr=sr, mono=True)\n",
    "            return y.astype(np.float32)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return np.zeros(int(sr * 0.5), dtype=np.float32)\n",
    "\n",
    "\n",
    "def synthesize_text(text: str, sr: int = 24000) -> tuple[np.ndarray, int]:\n",
    "    chunks = chunk_text(text)\n",
    "    parts = []\n",
    "    for ch in chunks:\n",
    "        lang = detect_lang_safe(ch)\n",
    "        parts.append(synthesize_chunk(ch, lang, sr=sr))\n",
    "    y = np.concatenate(parts) if parts else np.zeros(int(sr * 0.5), dtype=np.float32)\n",
    "    peak = np.max(np.abs(y)) or 1.0\n",
    "    y = y / peak * 0.95\n",
    "    return y.astype(np.float32), sr\n",
    "\n",
    "# ---------------------------\n",
    "# Audio FX\n",
    "# ---------------------------\n",
    "def apply_gain_db(y: np.ndarray, db: float) -> np.ndarray:\n",
    "    factor = 10 ** (db / 20.0)\n",
    "    out = y * factor\n",
    "    maxv = np.max(np.abs(out))\n",
    "    if maxv > 1.0:\n",
    "        out = out / maxv * 0.99\n",
    "    return out.astype(np.float32)\n",
    "\n",
    "\n",
    "def apply_speed(y: np.ndarray, sr: int, speed: float) -> np.ndarray:\n",
    "    speed = max(0.25, min(2.0, float(speed)))\n",
    "    return librosa.effects.time_stretch(y, rate=speed).astype(np.float32)\n",
    "\n",
    "\n",
    "def apply_pitch(y: np.ndarray, sr: int, semitones: float) -> np.ndarray:\n",
    "    return librosa.effects.pitch_shift(y, sr=sr, n_steps=semitones).astype(np.float32)\n",
    "\n",
    "\n",
    "def bandpass(y: np.ndarray, sr: int, center_hz: float, q: float = 1.0) -> np.ndarray:\n",
    "    center_hz = float(np.clip(center_hz, 20.0, min(20000.0, sr/2 - 100)))\n",
    "    bw = center_hz / max(q, 0.1)\n",
    "    low = max(10.0, center_hz - bw/2)\n",
    "    high = min(sr/2 - 10.0, center_hz + bw/2)\n",
    "    if low >= high:\n",
    "        return y\n",
    "    sos = butter(4, [low/(sr/2), high/(sr/2)], btype='bandpass', output='sos')\n",
    "    return sosfilt(sos, y).astype(np.float32)\n",
    "\n",
    "# ---------------------------\n",
    "# Session State\n",
    "# ---------------------------\n",
    "class Session:\n",
    "    def __init__(self):\n",
    "        self.y_full = None\n",
    "        self.sr = 24000\n",
    "        self.offset = 0.0\n",
    "        self.last_processed = None\n",
    "\n",
    "    def load_text(self, text: str):\n",
    "        y, sr = synthesize_text(text)\n",
    "        self.y_full, self.sr = y, sr\n",
    "        self.offset = 0.0\n",
    "        self.last_processed = None\n",
    "\n",
    "    def load_file(self, path: str):\n",
    "        text = extract_text(path)\n",
    "        self.load_text(text)\n",
    "\n",
    "    def process(self, speed=1.0, gain_db=0.0, pitch_semitones=0.0, center_hz=1000.0, q=1.0):\n",
    "        if self.y_full is None:\n",
    "            return None, None\n",
    "        y = self.y_full.copy()\n",
    "        if pitch_semitones:\n",
    "            y = apply_pitch(y, self.sr, pitch_semitones)\n",
    "        if speed and abs(speed - 1.0) > 1e-3:\n",
    "            y = apply_speed(y, self.sr, speed)\n",
    "        if center_hz:\n",
    "            y = bandpass(y, self.sr, center_hz, q)\n",
    "        if gain_db:\n",
    "            y = apply_gain_db(y, gain_db)\n",
    "        self.last_processed = (y, self.sr)\n",
    "        return y, self.sr\n",
    "\n",
    "    def slice_from_offset(self, y: np.ndarray, sr: int) -> np.ndarray:\n",
    "        start = int(self.offset * sr)\n",
    "        start = max(0, min(start, len(y)))\n",
    "        return y[start:]\n",
    "\n",
    "    def save_wav(self, y: np.ndarray, sr: int) -> str:\n",
    "        fp = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "        sf.write(fp.name, y, sr)\n",
    "        fp.flush()\n",
    "        return fp.name\n",
    "\n",
    "SESSION = Session()\n",
    "\n",
    "# ---------------------------\n",
    "# Gradio Callbacks\n",
    "# ---------------------------\n",
    "\n",
    "def ui_load_text(text):\n",
    "    SESSION.load_text(text)\n",
    "    return gr.update(value=\"Loaded text.\"), \"\"\n",
    "\n",
    "\n",
    "def ui_load_file(file):\n",
    "    if file is None:\n",
    "        return gr.update(), \"\"\n",
    "    SESSION.load_file(file.name)\n",
    "    return gr.update(value=\"Loaded file.\"), \"\"\n",
    "\n",
    "\n",
    "def ui_process(speed, gain_db, pitch_semitones, center_hz, wavelength, q):\n",
    "    # wavelength <-> frequency sync\n",
    "    if wavelength:\n",
    "        center_hz = 343.0 / max(0.017, min(17.15, float(wavelength)))\n",
    "    y, sr = SESSION.process(speed, gain_db, pitch_semitones, center_hz, q)\n",
    "    if y is None:\n",
    "        return None, \"No audio yet.\"\n",
    "    sliced = SESSION.slice_from_offset(y, sr)\n",
    "    wav_path = SESSION.save_wav(sliced, sr)\n",
    "    lam = 343.0 / max(1.0, center_hz)\n",
    "    return wav_path, f\"Offset: {SESSION.offset:.1f}s, Length: {len(sliced)/sr:.1f}s | λ≈{lam:.3f}m\"\n",
    "\n",
    "\n",
    "def ui_seek(delta):\n",
    "    SESSION.offset = max(0.0, SESSION.offset + float(delta))\n",
    "    if SESSION.last_processed is None:\n",
    "        return None, f\"Offset: {SESSION.offset:.1f}s\"\n",
    "    y, sr = SESSION.last_processed\n",
    "    sliced = SESSION.slice_from_offset(y, sr)\n",
    "    wav_path = SESSION.save_wav(sliced, sr)\n",
    "    return wav_path, f\"Offset: {SESSION.offset:.1f}s, Length: {len(sliced)/sr:.1f}s\"\n",
    "\n",
    "\n",
    "def ui_reset_offset():\n",
    "    SESSION.offset = 0.0\n",
    "    return ui_seek(0)\n",
    "\n",
    "# ---------------------------\n",
    "# Build Gradio Interface with Sweet Girl Defaults\n",
    "# ---------------------------\n",
    "with gr.Blocks(title=\"Multilingual TTS Reader + Player\") as demo:\n",
    "    gr.Markdown(\"# Multilingual TTS Reader + Player\\nDefault voice preset is a sweet girl's voice (Pitch +5, Tone 3000 Hz, Gain −2 dB). Adjust any sliders to override.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(label=\"Paste Text\", lines=6)\n",
    "        file = gr.File(label=\"Or upload: PDF/DOCX/PPTX/TXT\")\n",
    "    with gr.Row():\n",
    "        load_text_btn = gr.Button(\"Load Text\")\n",
    "        load_file_btn = gr.Button(\"Load File\")\n",
    "        load_status = gr.Textbox(label=\"Loader Status\", interactive=False)\n",
    "\n",
    "    with gr.Row():\n",
    "        speed = gr.Slider(0.25, 2.0, value=1.0, step=0.05, label=\"Speed (x)\")\n",
    "        gain = gr.Slider(-30, 12, value=-2, step=1, label=\"Loudness / Gain (dB)\")\n",
    "        pitch = gr.Slider(-12, 12, value=5, step=0.5, label=\"Pitch Shift (semitones)\")\n",
    "    with gr.Row():\n",
    "        center = gr.Slider(20, 20000, value=3000, step=1, label=\"Tone Center Frequency (Hz)\")\n",
    "        wavelength = gr.Slider(0.017, 17.15, value=0.114, step=0.001, label=\"Wavelength (m)\")\n",
    "        q = gr.Slider(0.2, 10.0, value=1.0, step=0.1, label=\"Tone Q (bandwidth)\")\n",
    "\n",
    "    process_btn = gr.Button(\"Process + Play from Offset\")\n",
    "    audio = gr.Audio(label=\"Audio Output\", interactive=False)\n",
    "    status = gr.Textbox(label=\"Playback Status\", interactive=False)\n",
    "\n",
    "    with gr.Row():\n",
    "        back10 = gr.Button(\"⏪ Rewind 10s\")\n",
    "        ahead10 = gr.Button(\"⏩ Forward 10s\")\n",
    "        reset = gr.Button(\"⏮️ Restart\")\n",
    "\n",
    "    # Events\n",
    "    load_text_btn.click(ui_load_text, inputs=[txt], outputs=[load_status, txt])\n",
    "    load_file_btn.click(ui_load_file, inputs=[file], outputs=[load_status, txt])\n",
    "    process_btn.click(ui_process, inputs=[speed, gain, pitch, center, wavelength, q], outputs=[audio, status])\n",
    "    back10.click(lambda: ui_seek(-10), outputs=[audio, status])\n",
    "    ahead10.click(lambda: ui_seek(10), outputs=[audio, status])\n",
    "    reset.click(ui_reset_offset, outputs=[audio, status])\n",
    "\n",
    "# In Jupyter, launch with:\n",
    "demo.launch(debug=False, share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a966761-eb9d-418e-a089-699a16a395b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
